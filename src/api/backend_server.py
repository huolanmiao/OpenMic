"""
Web APIæ¨¡å— (ä»»åŠ¡å›› - å®Œæ•´å®ç°ï¼šæ–‡æœ¬ç”Ÿæˆ + è¯­éŸ³åˆæˆ)
FastAPIåç«¯APIå®ç°
"""

import uuid
import io
import base64
import numpy as np
from scipy.io.wavfile import write
from typing import Optional, List, Dict
from enum import Enum
from datetime import datetime

from fastapi import FastAPI, HTTPException, BackgroundTasks
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel, Field

# --- å¼•å…¥ä½ çš„æ ¸å¿ƒé€»è¾‘ ---
try:
    from src.orchestrator import ComedyGroupChat
    from src.speech import StandupSpeechPipeline  # æ–°å¢
    from src.config import config_manager
except ImportError:
    print("âš ï¸ è­¦å‘Š: æœªæ‰¾åˆ° src æ¨¡å—ï¼Œè¯·ç¡®ä¿åœ¨é¡¹ç›®æ ¹ç›®å½•ä¸‹è¿è¡Œ")

# --- å…¨å±€å˜é‡ ---
TASKS: Dict[str, dict] = {}

# è¯­éŸ³ç®¡é“å•ä¾‹ (é¿å…é‡å¤åŠ è½½æ¨¡å‹)
SPEECH_PIPELINE: Optional['StandupSpeechPipeline'] = None

def get_speech_pipeline():
    """è·å–æˆ–åˆå§‹åŒ–è¯­éŸ³ç®¡é“"""
    global SPEECH_PIPELINE
    if SPEECH_PIPELINE is None:
        print("ğŸ”Š æ­£åœ¨åˆå§‹åŒ–è¯­éŸ³ç”Ÿæˆæ¨¡å‹ (é¦–æ¬¡è¿è¡Œå¯èƒ½è¾ƒæ…¢)...")
        # è¿™é‡Œä½¿ç”¨é»˜è®¤é…ç½®åˆå§‹åŒ–ï¼Œå¦‚æœéœ€è¦åŠ¨æ€keyï¼Œå¯ä»¥åœ¨ run æ—¶å¤„ç†æˆ–é‡æ–°è®¾è®¡
        SPEECH_PIPELINE = StandupSpeechPipeline(
            device="cuda",  # å¦‚æœæŠ¥é”™è¯·æ”¹ä¸º "cpu"
            llm_config=config_manager.get_autogen_llm_config()
        )
        print("âœ… è¯­éŸ³æ¨¡å‹åŠ è½½å®Œæˆ")
    return SPEECH_PIPELINE


# --- Pydanticæ¨¡å‹å®šä¹‰ ---

class ComedyStyle(str, Enum):
    OBSERVATION = "è§‚å¯Ÿç±»"
    SELF_DEPRECATION = "è‡ªå˜²ç±»"
    ROAST = "åæ§½ç±»"

class GenerationRequest(BaseModel):
    """æ–‡æœ¬ç”Ÿæˆè¯·æ±‚"""
    topic: str = Field(..., description="ä¸»é¢˜")
    style: ComedyStyle = Field(default=ComedyStyle.OBSERVATION)
    duration_minutes: int = Field(default=3)
    target_audience: str = Field(default="å¹´è½»äºº")
    api_key: Optional[str] = None

class AudioGenerationRequest(BaseModel):
    """æ–°å¢ï¼šéŸ³é¢‘ç”Ÿæˆè¯·æ±‚"""
    script: str = Field(..., description="è¦æœ—è¯»çš„å‰§æœ¬å†…å®¹")
    voice_id: str = Field(default="random", description="éŸ³è‰²ID")
    api_key: Optional[str] = None

class TaskResponse(BaseModel):
    task_id: str
    status: str
    message: str

class TaskStatus(BaseModel):
    task_id: str
    status: str
    progress: float
    current_stage: Optional[str]
    result: Optional[dict] = None


# --- åå°ä»»åŠ¡é€»è¾‘ ---
async def process_text_task(task_id: str, request: GenerationRequest):
    """
    å¤„ç†æ–‡æœ¬ç”Ÿæˆçš„åå°ä»»åŠ¡
    """
    try:
        # âœ¨ å®šä¹‰å›è°ƒå‡½æ•°ï¼šä¾›æ™ºèƒ½ä½“å†…éƒ¨è°ƒç”¨
        def update_task_progress(stage_name: str, progress_val: float):
            if task_id in TASKS:
                TASKS[task_id]["current_stage"] = stage_name
                TASKS[task_id]["progress"] = progress_val
                # åŒæ—¶ä¹Ÿè®°å½•åœ¨åå°æ—¥å¿—ï¼Œæ–¹ä¾¿è°ƒè¯•
                print(f"DEBUG [Task {task_id[:8]}]: {stage_name} ({progress_val*100:.0f}%)")

        # åˆå§‹çŠ¶æ€æ›´æ–°
        update_task_progress("æ­£åœ¨åˆå§‹åŒ–å¤šæ™ºèƒ½ä½“é…ç½®...", 0.05)
        
        # è·å–é…ç½®
        llm_config = config_manager.get_autogen_llm_config()
        if request.api_key and request.api_key.strip():
            # åŠ¨æ€è¦†ç›– API Key (é€»è¾‘åŒå‰)
            if "config_list" in llm_config:
                for config in llm_config["config_list"]:
                    config["api_key"] = request.api_key
        
        # âœ¨ å…³é”®ï¼šå°†å›è°ƒå‡½æ•° update_task_progress ä¼ ç»™ ComedyGroupChat
        team = ComedyGroupChat(
            llm_config=llm_config,
            max_round=25,
            on_step_change=update_task_progress  # ç»‘å®šå›è°ƒ
        )
        
        # è¿è¡Œåˆ›ä½œæµç¨‹
        # ç°åœ¨ï¼Œteam å†…éƒ¨æ¯ä¸€æ­¥è°ƒç”¨ self.on_step_changeï¼Œéƒ½ä¼šæ›´æ–° TASKS å­—å…¸
        result = await team.run_async(
            topic=request.topic,
            style=request.style.value,
            duration_minutes=request.duration_minutes,
            target_audience=request.target_audience
        )
        
        # import json
        # with open("/data/ctl/projects/OpenMic/outputs/comedy_20260109_130803.json", 'r') as f:
        #     result = json.load(f)
        # ä»»åŠ¡å®Œæˆåçš„æœ€ç»ˆå¤„ç†
        final_script = result.get("final_script") or result.get("performance_markers")
        
        TASKS[task_id]["result"] = {"script": final_script}
        TASKS[task_id]["status"] = "completed"
        TASKS[task_id]["progress"] = 1.0
        TASKS[task_id]["current_stage"] = "å‰§æœ¬åˆ›ä½œå·²å®Œæˆï¼Œå¯ä»¥ç”ŸæˆéŸ³é¢‘äº†"
        
    except Exception as e:
        TASKS[task_id]["status"] = "failed"
        TASKS[task_id]["current_stage"] = f"åˆ›ä½œè¿‡ç¨‹ä¸­æ–­: {str(e)}"
        import traceback
        traceback.print_exc()

async def process_audio_task(task_id: str, request: AudioGenerationRequest):
    """æ–°å¢ï¼šå¤„ç†éŸ³é¢‘ç”Ÿæˆ"""
    try:
        TASKS[task_id]["status"] = "processing"
        TASKS[task_id]["progress"] = 0.1
        TASKS[task_id]["current_stage"] = "åŠ è½½è¯­éŸ³å¼•æ“..."
        
        # 1. è·å–ç®¡é“ (ç¬¬ä¸€æ¬¡ä¼šæ¯”è¾ƒæ…¢)
        pipeline = get_speech_pipeline()
        
        # å¦‚æœç”¨æˆ·ä¼ äº† Keyï¼Œè¿™é‡Œå¯èƒ½éœ€è¦ä¸´æ—¶æ›´æ–°é…ç½®ï¼Œ
        # ä½†ç”±äº Pipeline åˆå§‹åŒ–è¾ƒé‡ï¼Œæš‚å¤ç”¨åˆå§‹åŒ–æ—¶çš„é…ç½®ï¼Œæˆ–è€…ä»…ç”¨äº LLM æ¶¦è‰²éƒ¨åˆ†
        
        TASKS[task_id]["progress"] = 0.3
        TASKS[task_id]["current_stage"] = "æ­£åœ¨æ ¹æ®è¯­å¢ƒè°ƒæ•´è¯­è°ƒ..."
        
        if request.voice_id and request.voice_id != "random":
            pipeline.set_voice(request.voice_id)
        
        # 2. è¿è¡Œç®¡é“
        # return_text=True ä¼šè¿”å›æ¶¦è‰²åçš„æ–‡æœ¬ï¼ˆå¢åŠ äº†è¯­æ°”è¯ç­‰ï¼‰
        print(f"å¼€å§‹ç”ŸæˆéŸ³é¢‘ï¼Œæ–‡æœ¬é•¿åº¦: {len(request.script)}")
        result = pipeline.run(request.script, return_text=True, return_control=True)
        
        TASKS[task_id]["progress"] = 0.8
        TASKS[task_id]["current_stage"] = "éŸ³é¢‘ç¼–ç ä¸­..."
        
        # 3. å¤„ç†éŸ³é¢‘æ•°æ® (NumPy -> WAV -> Base64)
        audio_data = result["audio"]
        sample_rate = 16000
        
        # å½’ä¸€åŒ–å¹¶è½¬ä¸º 16-bit æ•´æ•°
        scaled_audio = (audio_data * 32767).astype(np.int16)
        
        # å†™å…¥å†…å­˜ Buffer
        wav_buffer = io.BytesIO()
        write(wav_buffer, sample_rate, scaled_audio)
        wav_bytes = wav_buffer.getvalue()
        
        # è½¬ Base64
        audio_b64 = base64.b64encode(wav_bytes).decode('utf-8')
        audio_url = f"data:audio/wav;base64,{audio_b64}"
        
        TASKS[task_id]["result"] = {
            "audio_url": audio_url,
            "refined_text": result.get("text", ""), # åŒ…å«è¯­æ°”æ ‡æ³¨çš„æ–‡æœ¬
            "duration_seconds": len(audio_data) / sample_rate
        }
        TASKS[task_id]["status"] = "completed"
        TASKS[task_id]["progress"] = 1.0
        TASKS[task_id]["current_stage"] = "éŸ³é¢‘ç”Ÿæˆå®Œæˆ"
        
    except Exception as e:
        print(f"éŸ³é¢‘ä»»åŠ¡å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        TASKS[task_id]["status"] = "failed"
        TASKS[task_id]["current_stage"] = f"é”™è¯¯: {str(e)}"


# --- FastAPIåº”ç”¨ ---

def create_app() -> FastAPI:
    app = FastAPI(title="OpenMic API", version="0.2.0")
    
    app.add_middleware(
        CORSMiddleware,
        allow_origins=["*"],
        allow_credentials=True,
        allow_methods=["*"],
        allow_headers=["*"],
    )
    
    @app.post("/generate", response_model=TaskResponse)
    async def generate_comedy(request: GenerationRequest, bg_tasks: BackgroundTasks):
        """æ­¥éª¤1ï¼šç”Ÿæˆå‰§æœ¬"""
        task_id = str(uuid.uuid4())
        TASKS[task_id] = {
            "task_id": task_id, "status": "pending", "progress": 0.0,
            "current_stage": "å‡†å¤‡ç”Ÿæˆå‰§æœ¬", "result": None
        }
        bg_tasks.add_task(process_text_task, task_id, request)
        return {"task_id": task_id, "status": "pending", "message": "å‰§æœ¬ç”Ÿæˆä»»åŠ¡å·²æäº¤"}

    @app.post("/generate_audio", response_model=TaskResponse)
    async def generate_audio(request: AudioGenerationRequest, bg_tasks: BackgroundTasks):
        """æ­¥éª¤2ï¼šç”ŸæˆéŸ³é¢‘ (æ–°å¢æ¥å£)"""
        task_id = str(uuid.uuid4())
        TASKS[task_id] = {
            "task_id": task_id, "status": "pending", "progress": 0.0,
            "current_stage": "å‡†å¤‡ç”ŸæˆéŸ³é¢‘", "result": None
        }
        bg_tasks.add_task(process_audio_task, task_id, request)
        return {"task_id": task_id, "status": "pending", "message": "éŸ³é¢‘ç”Ÿæˆä»»åŠ¡å·²æäº¤"}
    
    @app.get("/tasks/{task_id}", response_model=TaskStatus)
    async def get_task_status(task_id: str):
        task = TASKS.get(task_id)
        if not task: raise HTTPException(404, "ä»»åŠ¡ä¸å­˜åœ¨")
        return task
    
    @app.get("/tasks/{task_id}/result")
    async def get_task_result(task_id: str):
        task = TASKS.get(task_id)
        if not task or task["status"] != "completed":
            raise HTTPException(400, "ä»»åŠ¡æœªå®Œæˆæˆ–ä¸å­˜åœ¨")
        return task["result"]
    
    @app.get("/voices")
    async def list_voices():
        """è·å–å¯ç”¨éŸ³è‰²åˆ—è¡¨"""
        try:
            pipeline = get_speech_pipeline()
            voices = pipeline.list_voices()
            
            formatted_voices = []
            for k, v in voices.items():
                # æ ¸å¿ƒä¿®æ”¹ï¼šä¼˜å…ˆä½¿ç”¨ comment ä½œä¸ºåå­—
                # å¦‚æœ comment æ˜¯ "æˆç†Ÿç”·å£°"ï¼ŒID æ˜¯ "spk_1"
                # æ˜¾ç¤ºåç§°å°±ä¼šå˜æˆï¼š"æˆç†Ÿç”·å£° (spk_1)" è¿™æ ·æ—¢ç›´è§‚åˆæœ‰åŒºåˆ†åº¦
                comment = v.get('comment')
                
                if comment:
                    # æœ‰æè¿°æ—¶ï¼šåªæ˜¾ç¤ºæè¿°å’Œæ€§åˆ«ï¼ŒIDæ”¾åé¢æˆ–è€…ä¸æ”¾
                    # ä¾‹å¦‚: "å¼€æœ—å¤§å” (Male) - spk_1"
                    display_name = f"{comment}"
                else:
                    # æ²¡æè¿°æ—¶å›é€€åˆ° ID
                    display_name = f"{k}"

                formatted_voices.append({
                    "id": k,            # ä¼ ç»™ç®—æ³•çš„çœŸå®ID
                    "name": display_name, # ç»™å‰ç«¯æ˜¾ç¤ºçš„å‹å¥½åç§°
                    "comment": comment or ""
                })

            return {"voices": formatted_voices}

        except Exception as e:
            print(f"è·å–éŸ³è‰²å¤±è´¥: {e}")
            # å‡ºé”™æ—¶çš„é»˜è®¤è¿”å›ä¹Ÿè¦æ”¹å¾—å‹å¥½ä¸€ç‚¹
            return {"voices": [{"id": "random", "name": "é»˜è®¤éŸ³è‰² (éšæœºé€‰æ‹©)", "comment": "ç³»ç»Ÿè‡ªåŠ¨é€‰æ‹©"}]}
            
    return app

if __name__ == "__main__":
    import uvicorn
    app = create_app()
    uvicorn.run(app, host="0.0.0.0", port=8000)